[{"authors":["admin"],"categories":null,"content":"I am a postdoctoral researcher in the Fellay Lab at EPFL, where I analyse human genomic data in the context of infectious diseases.\nMy interests include statistical modelling, statistical genetics, programming with R, reproducible analysis workflows, and topics intersecting health, medicine and technology.\nI received my PhD in Life Sciences in 2018 from the University of Lausanne, where I worked on the imputation of GWAS summary statistics supervised by Zoltán Kutalik.\nWhat I enjoy the most about applied statistics is the interdisciplinary aspect of collaborations that allows me to glimpse into different domains.\nIn my spare time, I enjoy exploring nature on a bike and contributing to open-source projects.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://sinarueeger.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a postdoctoral researcher in the Fellay Lab at EPFL, where I analyse human genomic data in the context of infectious diseases.\nMy interests include statistical modelling, statistical genetics, programming with R, reproducible analysis workflows, and topics intersecting health, medicine and technology.\nI received my PhD in Life Sciences in 2018 from the University of Lausanne, where I worked on the imputation of GWAS summary statistics supervised by Zoltán Kutalik.","tags":null,"title":"Sina Rüeger","type":"author"},{"authors":null,"categories":null,"content":" I finished my PhD under the main supervison of Zolt\u0026#225;n Kutalik in September 2018.\nYou can download my thesis, or checkout the slides from my public defense.\nAbstract Increasing our knowledge about biology in humans is essential for advances in medicine, such as early-stage diagnoses of diseases, drug development, public health strategies, and precision medicine. One approach to tackle this task is, to collect data on different components of a biological mechanism of interest, link these parts and try to construct an underlying model that helps us to explain the disease. To collect data, DNA is measured and the status of a disease is recorded for each individual in a dedicated group of people. In a first step, an analyst compares for each genetic variant across the whole genome the genetic mutations between people with the disease and healthy people; this is called a genome-wide association study (GWAS). Such first association screens rarely point right away to the true causal variants, but combined with additional biomedical (-omics) data and additional statistical methods it is possible to narrow down the true cause and gain insight into the biology of a disease. For example, by using GWAS results for two diseases (e.g. cardiovascular disease and obesity) and a statistical method called Mendelian randomisation, we are able to examine the causal effect of obesity on cardiovascular disease, or vice versa. These statistical follow-up investigations often require GWAS results for genetic variants than were unmeasured. During my PhD, I investigated a method called summary statistic imputation that precisely aims to solve the problem of inferring GWAS results for unmeasured genetic variants. Summary statistic imputation uses GWAS results and data from public sequencing data. My main findings were that imputation accuracy varies depending on certain characteristics of a genetic variant (e.g. low accuracy for rare mutations), as well as the size of publicly available sequencing data (low accuracy for small sized sequencing data). A further finding is, that summary statistic imputation can compete with imputation techniques that are based on individual-level data for certain subgroups of genetic variants (e.g. common variants).\nWith the help of summary statistic imputation researchers can facilitate follow-up investigations and thus gain more insight into the biology of diseases.\n","date":1558994400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558994400,"objectID":"070d51a28892f81411bee8389f825d6d","permalink":"https://sinarueeger.github.io/project/phd-thesis/","publishdate":"2019-05-28T00:00:00+02:00","relpermalink":"/project/phd-thesis/","section":"project","summary":"PhD thesis material.","tags":["statistical genetics"],"title":"Integrative Statistical Analysis of -omics and GWAS data","type":"project"},{"authors":null,"categories":null,"content":"","date":1558994400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558994400,"objectID":"1015e5348459ba232b9c99a584dbf21b","permalink":"https://sinarueeger.github.io/project/gwas.utils/","publishdate":"2019-05-28T00:00:00+02:00","relpermalink":"/project/gwas.utils/","section":"project","summary":"Helper functions when working with GWAS (summary) data.","tags":["statistical genetics","R"],"title":"R-package GWAS.utils","type":"project"},{"authors":null,"categories":null,"content":"","date":1558994400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558994400,"objectID":"0673e061ae94badb51ab44d83f8b8852","permalink":"https://sinarueeger.github.io/project/gggwas/","publishdate":"2019-05-28T00:00:00+02:00","relpermalink":"/project/gggwas/","section":"project","summary":"ggplot2 extension for visualising GWAS summary statistics.","tags":["statistical genetics","data visualisation","R"],"title":"R-package ggGWAS","type":"project"},{"authors":null,"categories":null,"content":"","date":1558994400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558994400,"objectID":"2a64e5712fe7bfd61bd034d3051a241e","permalink":"https://sinarueeger.github.io/project/stat-genetics-ressources/","publishdate":"2019-05-28T00:00:00+02:00","relpermalink":"/project/stat-genetics-ressources/","section":"project","summary":"Collection of resources needed in statistical genetics: data, readings, software.","tags":["statistical genetics"],"title":"Statistical Genetics Resources","type":"project"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://sinarueeger.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   ","date":1544464800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544464800,"objectID":"d124c794115c91ba7343c2dc6d794b27","permalink":"https://sinarueeger.github.io/talk/r-ladies/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/talk/r-ladies/","section":"talk","summary":" Click on the Slides button above to view the built-in slides feature.   ","tags":["workflow","R","R-Ladies"],"title":"Introduction to Drake","type":"talk"},{"authors":null,"categories":null,"content":"         Goal Get started Data Add geographical coordinates Create leaflet Save the map Reason for deviation from the original   This post provides the R-Code to map the 26 populations of the 1000 Genomes project.\nGoal Create a map similar to the one1 on the front page of http://www.internationalgenome.org/ in a reproducible manner.\nVersion on internationalgenome.org\n  Get started Packages needed:\n## accessed via :: # library(mapview) # library(readxl) # library(readr) # library(purrr) # library(tidyr) # library(forcats) library(leaflet) library(dplyr) library(ggmap) ## for geocode, devtools::install_github(\u0026quot;dkahle/ggmap\u0026quot;) ggmap requires a google map api key2:\nget one here: https://developers.google.com/maps/documentation/geocoding/get-api-key then run register_google(key = \"my_api_key\")   Data  The population counts and labels are from ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/ (download xlsx file). The super population labels are from here (pasted into a csv, then location was inferred).  Download the population counts and labels first:\nurl \u0026lt;- \u0026quot;ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_sample_info.xlsx\u0026quot; url.bitly \u0026lt;- \u0026quot;http://bit.ly/2MQTr02\u0026quot; download.file(url, \u0026quot;20130606_sample_info.xlsx\u0026quot;, mode = \u0026quot;wb\u0026quot;) Import file into R:\ndf \u0026lt;- readxl::read_excel(\u0026quot;20130606_sample_info.xlsx\u0026quot;, sheet = \u0026quot;Sample Info\u0026quot;) # \u0026gt;\u0026gt; Sample Info Some data wrangling:\n## count number of individuals by population ## rename population \u0026gt; POP n.pop \u0026lt;- df %\u0026gt;% group_by(Population) %\u0026gt;% summarise(n = n()) %\u0026gt;% rename(POP = Population) ## import super population names and details to the location of populations ## copied from here: url.spop \u0026lt;- \u0026quot;http://www.internationalgenome.org/faq/which-populations-are-part-your-study/\u0026quot; ## added location manually (!) - found this the only option to prevent overlapping locations. ## Also, description involves a mix of location and origin. ## rename superpopulation \u0026gt; SPOP n.spop \u0026lt;- readr::read_csv(\u0026quot;../../static/post/2018-12-05-1000genomes-map/sample_info_superpop.csv\u0026quot;) %\u0026gt;% rename(POP = `Population Code`, SPOP = `Super Population Code`) ## join the two information n.1kg \u0026lt;- left_join(n.pop, n.spop, by = c(\u0026quot;POP\u0026quot; = \u0026quot;POP\u0026quot;))  Add geographical coordinates Parts of the code below is from a map created by Daniela Vazquez for R-Ladies: https://github.com/rladies/Map-RLadies-Growing.\nThis is the part where we annotate the dataframe n.1kg with where the individuals live (not their ancestry). Repeat this until there are no warnings() about QUERY LIMITS (the while loop takes care of this).\nWe will use the ggmap package, which accesses the google maps api.\nA workaround is to set source = \"dsk\" (works for a limited number of queries)3.\nn.1kg \u0026lt;- n.1kg %\u0026gt;% mutate(purrr::map(.$location, geocode, source = \u0026quot;dsk\u0026quot;)) %\u0026gt;% tidyr::unnest() ## running into the inevitable QUERY LIMITS problems, lets use the approach from https://github.com/rladies/Map-RLadies-Growing n.1kg.withloc \u0026lt;- n.1kg %\u0026gt;% filter(!is.na(lon)) while(nrow(n.1kg.withloc) != nrow(n.1kg)) { # repeat this until there are no warnings() about QUERY LIMITS temp \u0026lt;- n.1kg %\u0026gt;% select(-lon, -lat) %\u0026gt;% anti_join(n.1kg.withloc %\u0026gt;% select(-lon, -lat)) %\u0026gt;% mutate(longlat = purrr::map(.$location, geocode, source = \u0026quot;dsk\u0026quot;)) %\u0026gt;% tidyr::unnest() %\u0026gt;% filter(!is.na(lon)) n.1kg.withloc \u0026lt;- n.1kg.withloc %\u0026gt;% bind_rows(temp) %\u0026gt;% distinct() } n.1kg \u0026lt;- n.1kg.withloc ## glue POP and `Population Description` together n.1kg \u0026lt;- n.1kg %\u0026gt;% mutate(pop.desc = paste0(POP, \u0026quot; : \u0026quot;, `Population Description`, \u0026quot; (\u0026quot;, SPOP, \u0026quot;)\u0026quot;)) ## given that only a number of geolocation are possible with the google API, this ## should probably stored out ## readr::write_csv(n.1kg, path = \u0026quot;1kg_sample_info_location.csv\u0026quot;)  Create leaflet Map locations a world map with leaflet\n## if you have stroed the data in the previous chunk: ## readr::read_csv(\u0026quot;1kg_sample_info_location.csv\u0026quot;) Define shiny icons:\nicons \u0026lt;- awesomeIcons( icon = \u0026#39;user\u0026#39;, #people\u0026#39;, iconColor = \u0026#39;black\u0026#39;, library = \u0026#39;fa\u0026#39;, #ion markerColor = as.character(forcats::fct_recode(as.factor(n.1kg$SPOP), red = \u0026quot;EUR\u0026quot;, blue = \u0026quot;AFR\u0026quot;, green = \u0026quot;AMR\u0026quot;, gray = \u0026quot;EAS\u0026quot;, orange = \u0026quot;SAS\u0026quot;)) ## ok, thats not too pretty, but turns out, hex colors won\u0026#39;t work ) ## we need to create a vector that maps cols to SPOP from the markerColor argument above cols \u0026lt;- c(\u0026quot;#E50102\u0026quot;, \u0026quot;#00A9DD\u0026quot;, \u0026quot;#57BA1F\u0026quot;, \u0026quot;#575757\u0026quot;, \u0026quot;#FD8E00\u0026quot;) SPOP \u0026lt;- c(\u0026quot;EUR\u0026quot;, \u0026quot;AFR\u0026quot;, \u0026quot;AMR\u0026quot;, \u0026quot;EAS\u0026quot;, \u0026quot;SAS\u0026quot;) ## separate icon that will display the information ## ------------------------------------------------ icon.info \u0026lt;- awesomeIcons( icon = \u0026#39;info\u0026#39;, #people\u0026#39;, iconColor = \u0026#39;white\u0026#39;, library = \u0026#39;fa\u0026#39;, #ion markerColor = \u0026quot;white\u0026quot; ) Create map:\nm \u0026lt;- leaflet(data = n.1kg) %\u0026gt;% addTiles() %\u0026gt;% # Add default OpenStreetMap map tiles addAwesomeMarkers(lat=~lat, lng=~lon, label = ~htmltools::htmlEscape(pop.desc), icon = icons) %\u0026gt;% addAwesomeMarkers(lat=-45, lng=-107, popup = glue::glue(\u0026quot;Source: https://github.com/sinarueeger/map-1000genomes\u0026quot;), icon = icon.info) %\u0026gt;% ## this bit has potential to be displayed as a href. #glue::glue(\u0026quot;Source: {url.bitly} + {url.spop} (manual tidying)\u0026quot;), icon = icon.info) %\u0026gt;% addLegend(\u0026quot;bottomright\u0026quot;, colors =cols, labels= SPOP, opacity = 1) m # Print the map  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addAwesomeMarkers\",\"args\":[[13.16667,34.5003,24,22.08829,40.11995,39.9075,35,4,10,60.16952,50.416667,29.845783,13.5,40,54.75844,35.6895,10.75,0.60751,7.13833,34.05223,-10,31.54972,18.24829,55.9483399,43.41667,7.38778],[-59.53333,-111.50098,90,101.0248,-111.67031,116.39723,105,-72,8,24.93545,-4.75,-96.919704,-15.5,-4,-2.69531,139.69171,106.66667,34.76966,-11.67056,-118.24368,-76,74.34361,-66.49989,-3.1932723,11,3.89639],{\"icon\":\"user\",\"markerColor\":[\"blue\",\"blue\",\"orange\",\"gray\",\"red\",\"gray\",\"gray\",\"green\",\"blue\",\"red\",\"red\",\"orange\",\"blue\",\"red\",\"orange\",\"gray\",\"gray\",\"blue\",\"blue\",\"green\",\"green\",\"orange\",\"green\",\"orange\",\"red\",\"blue\"],\"iconColor\":\"black\",\"spin\":false,\"squareMarker\":false,\"iconRotate\":0,\"font\":\"monospace\",\"prefix\":\"fa\"},null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},null,null,null,null,[\"ACB : African Caribbeans in Barbados (AFR)\",\"ASW : Americans of African Ancestry in SW USA (AFR)\",\"BEB : Bengali from Bangladesh (SAS)\",\"CDX : Chinese Dai in Xishuangbanna, China (EAS)\",\"CEU : Utah Residents (CEPH) with Northern and Western European Ancestry (EUR)\",\"CHB : Han Chinese in Beijing, China (EAS)\",\"CHS : Southern Han Chinese (EAS)\",\"CLM : Colombians from Medellin, Colombia (AMR)\",\"ESN : Esan in Nigeria (AFR)\",\"FIN : Finnish in Finland (EUR)\",\"GBR : British in England and Scotland (EUR)\",\"GIH : Gujarati Indian from Houston, Texas (SAS)\",\"GWD : Gambian in Western Divisions in the Gambia (AFR)\",\"IBS : Iberian Population in Spain (EUR)\",\"ITU : Indian Telugu from the UK (SAS)\",\"JPT : Japanese in Tokyo, Japan (EAS)\",\"KHV : Kinh in Ho Chi Minh City, Vietnam (EAS)\",\"LWK : Luhya in Webuye, Kenya (AFR)\",\"MSL : Mende in Sierra Leone (AFR)\",\"MXL : Mexican Ancestry from Los Angeles USA (AMR)\",\"PEL : Peruvians from Lima, Peru (AMR)\",\"PJL : Punjabi from Lahore, Pakistan (SAS)\",\"PUR : Puerto Ricans from Puerto Rico (AMR)\",\"STU : Sri Lankan Tamil from the UK (SAS)\",\"TSI : Toscani in Italia (EUR)\",\"YRI : Yoruba in Ibadan, Nigeria (AFR)\"],{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]},{\"method\":\"addAwesomeMarkers\",\"args\":[-45,-107,{\"icon\":\"info\",\"markerColor\":\"white\",\"iconColor\":\"white\",\"spin\":false,\"squareMarker\":false,\"iconRotate\":0,\"font\":\"monospace\",\"prefix\":\"fa\"},null,null,{\"interactive\":true,\"draggable\":false,\"keyboard\":true,\"title\":\"\",\"alt\":\"\",\"zIndexOffset\":0,\"opacity\":1,\"riseOnHover\":false,\"riseOffset\":250},\"Source: https://github.com/sinarueeger/map-1000genomes\",null,null,null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},null]},{\"method\":\"addLegend\",\"args\":[{\"colors\":[\"#E50102\",\"#00A9DD\",\"#57BA1F\",\"#575757\",\"#FD8E00\"],\"labels\":[\"EUR\",\"AFR\",\"AMR\",\"EAS\",\"SAS\"],\"na_color\":null,\"na_label\":\"NA\",\"opacity\":1,\"position\":\"bottomright\",\"type\":\"unknown\",\"title\":null,\"extra\":null,\"layerId\":null,\"className\":\"info legend\",\"group\":null}]}],\"limits\":{\"lat\":[-45,60.16952],\"lng\":[-118.24368,139.69171]}},\"evals\":[],\"jsHooks\":[]}  Save the map ## save to png ## ------------ mapview::mapshot(m, file = \u0026quot;map-1000genomes-populations.png\u0026quot;) ## save to hmtl ## ------------- htmlwidgets::saveWidget(m, file=\u0026quot;map-1000genomes-populations.html\u0026quot;)  Reason for deviation from the original I mapped the populations according to the current location but coloured them according to ancestry.\n  This is a png and cannot be altered.↩\n Seen here: https://stackoverflow.com/questions/36175529/getting-over-query-limit-after-one-request-with-geocode.↩\n See https://stackoverflow.com/questions/36175529/getting-over-query-limit-after-one-request-with-geocode.↩\n   ","date":1543968000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543968000,"objectID":"5a079f2f8096ce6048f7aa7477164910","permalink":"https://sinarueeger.github.io/post/1kgmap/","publishdate":"2018-12-05T00:00:00Z","relpermalink":"/post/1kgmap/","section":"post","summary":"Goal Get started Data Add geographical coordinates Create leaflet Save the map Reason for deviation from the original   This post provides the R-Code to map the 26 populations of the 1000 Genomes project.\nGoal Create a map similar to the one1 on the front page of http://www.internationalgenome.org/ in a reproducible manner.\nVersion on internationalgenome.org\n  Get started Packages needed:","tags":["data visualisation","R","maps"],"title":"Create a map of the 1000 Genomes project reference populations","type":"post"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   ","date":1543921200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543921200,"objectID":"e2e2dbd61149f7b5ffc2983cea602799","permalink":"https://sinarueeger.github.io/talk/r-lunchs/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/talk/r-lunchs/","section":"talk","summary":" Click on the Slides button above to view the built-in slides feature.   ","tags":["workflow","best practices","R"],"title":"Workflow \u0026 best practices for projects","type":"talk"},{"authors":null,"categories":null,"content":"  What is a “project folder”? Why now? Why we tidy up: authority and incentive Challenges What I want The options Drake Getting started More Examples Resources  But wait: drake does not care about messy folders What is next? When is the right time to tidy Is it really worth it   Recently, I started to seriously1 think about the tidiness of data analysis project folders, and the implications of tidying up.\nI was lucky enough to talk about what I have figured out so far at the Genève R User Group. While I am not done yet with reflecting on this2, I wanted to write down my thoughts that lead to my presentation3. So what follows is just “thinking out loud”.\nUpdate: In February 2019, Amanda Dobbyn gave a talk at R-Ladies NYC about drake. All material here.\nTrailer. Your browser does not support the video tag.   Presentation trailer made with Maëlle Salmon’s instructions.   What is a “project folder”? To me a project folder is anything that contains the (R-)scripts necessary to run a data analysis and create the corresponding report. It is like a framed piece of work that you can take and place somewhere else. And probably it will take the form of the Figure from the R4DS book below:\n  Adapted from Figure in R4DS book.    Ideally you should be able to take that folder as it is, run it on another computer and get the same results. Unfortunately, this is not always the case - at least with my project folders.\nI think that the tidiness of a project folder, how it is structured and how it tells the user to execute what and when, correlate strongly with the whole repeatability, replicability and reproducibility aspect.\n Why now? The reason I started to dig deeper into workflow management possibilities in R, is, that I was changing jobs, and I had to clean up my old project folders from almost 5 years of analysing genetic data 😱. And so I faced this gigantic mess a bit of a mess, spread over several servers and computers, some version controlled, others not, with implemented “best practices” from different waves of trying to improve. I tried to clean up as good as I could, but I told myself that this would not happen again. At my new job I would use version control for everything and I would use something make-like (e.g. remake) to indicate the “recipe” of a project and be in control of what is recomputed and what is not4.\n Why we tidy up: authority and incentive I have a long-time interest in tidiness in general and from studying my own behaviour I came up with the theory that tidiness is only present when a) somebody tells you to do it, or b) you are rewarded for it.\nHere are some examples:\n If you want to compile an R-package you have little to no freedom in how to name folders. You must have a given folder and file structure. Otherwise it won’t compile. This dictated and unified folder structure makes it easy for R users to understand what is where in an R-package. No matter who coded it.    R package structure. Figure from http://r-pkgs.had.co.nz/package.html.     If you work on several different projects at them same time, it is beneficial to have structure, so that you can quickly dive back into a project.\n Following good practices also leaves you more time to do the fun stuff, like modelling and creating data visualisation.\n   Challenges I started by wondering why maintaining a tidy and coherent folder structure was so difficult for me to maintain. So I came up with a list (which is certainly going to change over time):\n Having different places for computation (Laptop, Server1, Server2, …). Not using git consistently. Unclear separation of the folders data (raw input data), processed-data and output-data (results). Data deliveries: data hardly ever arrives in one tidy folder, but instead comes at different time points and so poses other challenges. Having many different best practices implemented: so each project would have its own set of folder names and file naming convention, leading to little overview of the analysis and its iteration steps → cleaning, modelling, visualisation, reports. Using similar code in many different R scripts → redundant code. Having no punishment for not cleaning up (and also not really seeing the benefit).   What I want Then I asked myself what I want to achieve with implementing (and sticking to) something new.\nMaking it easy for colleagues at work to rerun (and understand) the project → “repeatability” Making it easy for others to rerun and to understand the project → “reproducibility”5 Making it easy for others to rerun the code with different data → “replicability”  Next I looked for solutions. First I would need to use coherent folder names. Second I would need to have a file that indicates the recipe of an analysis. Third, I would implement most free floating and redundant code into functions. Fourth, I would minimise unnecessary computation by caching results. Fifth, I would start using unit tests6.\n The options There are many different ready-to-use software packages out there. I was thinking of going back to using make, that I used years ago. Then I came across {remake}, which seemed just what I needed. A colleague at work was using stu and was recommending it. But then the Swiss Institute of Bioinformatics offered a course on Make-like declarative workflows with R taught by Kirill Müller, which I could not attend. Luckily, thanks to the awesome online course material, I could learn it by myself.\n Drake The presentation Make-like declarative workflows with R presented the R-package {drake} (drake = Data Frames in R for Make7).\n{Drake} was created by Will Landau and reviewed by rOpenSci. On the github page it says that {drake} is a “general-purpose workflow manager for data-driven tasks”. Sounds perfect!\nThe way I understand it, is, that it is based on make (and overlaps with the R-package {remake}). Therefore when making a change to an analysis and re-running it, it only re-compute the dependent parts. But compared to make, {drake} is much more convenient to use. Plus it is scalable to parallel computing. And it is intuitive to use, meaning, colleagues can learn it quickly.\nGetting started Best is, to run the mini example provided in the package, and then go from there. Drake has many other examples provided, you can check them by running drake::drake_examples().\ninstall.packages(\"drake\") Run drake::drake_example(\"main\") → this will download a folder called main. Go to the terminal. You can look at all the files contained in main by writing tree main (this works on MacOS)  main/ ├── COPYRIGHT.md ├── LICENSE.md ├── README.md ├── clean.R ├── make.R ├── raw_data.xlsx └── report.Rmd Next, open make.R. The key functions are drake_plan() and make(). Add the following bit before and after make(plan).  config \u0026lt;- drake_config(plan) vis_drake_graph(config)  Run all code for a first time. Change something (e.g. the plot function). Rerun and watch the colors change in vis_drake_graph(config). Use functions readd() and loadd() to work with the produced output. checkout .drake/ folder. This is where all the cached work is stored.  By running this example, you will see that drake_plan() is used to create a recipe of the analysis and make() is used to execute that recipe. make() will create objects, such as fit and hist in the example and store them in the folder .drake/.\nreadd() is used to return an object from cache. This is handy when we only want to diplay an object. loadd() on the other hand is used to load an object into our session (similarly to load).\n More To checkout further options I recommend - The slides from Christine Stawitz (presented at R-Ladies Seattle in June 2018). - The material by Amanda Dobbyn (presented at R-Ladies NYC in February 2019). (Update)\nBoth presentations provide a good overview of the options {drake} provides.\n Examples I also created some tiny examples that use genetic data. It has four folders:\nwild-west: this is how I was structuring folders till now (this example was used to introduce the analysis during the presentation). wild-west-pro: same as 1. but with an README.md. drake: implementing 1. into drake. drake-adv: implementing 1. into a more realistic, hierarchical folder structure.  The examples use genetic data that was originally used in the crowdAI openSNP height prediction challenge. The full openSNP data set was prepared by my colleague Olivier Naret and can be downloaded here. The examples use a small subset of the full dataset that can be downloaded here.\n Resources Here are a bunch of resources that helped me understand {drake}:\n Github Repo This tutorial and cheatsheet by Kirill Müller. Overview of options: Make-like declarative workflows with R by Christine Stawitz. Best practices for drake projects. Lots of tutorials and examples.    But wait: drake does not care about messy folders True! I can have a make.R file anywhere and it will still work. But I believe that the shift in logic that you have to get used to with {drake} makes you care more about folder structure.\n What is next? I am currently reading the PlosCompBio paper Good enough practices in scientific computing - great read, giving me lots of ideas!\nI want to use {drake} in a more complex setting. There are also other R-packages that help with project workflows. And I should invest some time to come up with a test suite for data analysis projects.\n When is the right time to tidy At the Genève RUG meetup we were also discussing when we think is the right time to tidy up.\nProject folders evolve over time. Especially in the beginning of a project, we are busy figuring things out, wrangling data, fitting models, making plots and telling people what we found out. This can take some time. But at one point we are ready to write a report.\nIt is probably at that stage (when we write a report) that we can “frame” that project into something that is “stable” and “portable”.\nAlthough - I am not sure we have to wait that long. I think the benefits of {drake} (e.g. caching) already help us at an earlier stage.\n Is it really worth it I think there is a trade-off between dedicating days to tidying up and not caring about structure at all. Same with tooling. For example, if we use a tool, say make but no one else but us knows how to use it, it is going to be hard for colleagues to understand and use project folders that use make. We have to keep that balance in mind.\n  Seriously, meaning, different from previous, half-hearted attempts.↩\n Just started reading Good enough practices in scientific computing - great paper!↩\n Thanks to Maëlle for pointing out that this is a good thing to do!↩\n And while at it, I would totally decrease my coffee consumption too and never procrastinate again 😉.↩\n The terminology is really confusing at times. I rely on this definition. ↩\n Thanks to my colleague for the idea!↩\n I am still wondering how “Data Frames in R for Make” adds up to “drake” 🤔.↩\n   ","date":1539043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539043200,"objectID":"6afbc2ff36dc45b7457de9036b143829","permalink":"https://sinarueeger.github.io/post/drake/","publishdate":"2018-10-09T00:00:00Z","relpermalink":"/post/drake/","section":"post","summary":"What is a “project folder”? Why now? Why we tidy up: authority and incentive Challenges What I want The options Drake Getting started More Examples Resources  But wait: drake does not care about messy folders What is next? When is the right time to tidy Is it really worth it   Recently, I started to seriously1 think about the tidiness of data analysis project folders, and the implications of tidying up.","tags":["drake","R","projects"],"title":"Tidying workflows in R","type":"post"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   ","date":1538672400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538672400,"objectID":"7c868d5e4adaad351525337d14504726","permalink":"https://sinarueeger.github.io/talk/geneve-rug/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/talk/geneve-rug/","section":"talk","summary":" Click on the Slides button above to view the built-in slides feature.   ","tags":["workflow","R"],"title":"Tidying workflows \u0026 R community","type":"talk"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   ","date":1536769800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536769800,"objectID":"fd0549ad004f2a2079c743f9f3a0a32d","permalink":"https://sinarueeger.github.io/talk/geek-girls-carrots/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/talk/geek-girls-carrots/","section":"talk","summary":" Click on the Slides button above to view the built-in slides feature.   ","tags":["R","introduction"],"title":"An introduction to (problem solving with) R","type":"talk"},{"authors":null,"categories":null,"content":" In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;\n","date":1536444000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536444000,"objectID":"6a451186c775f5f0adb3a0416d0cb711","permalink":"https://sinarueeger.github.io/tutorial/example/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/example/","section":"tutorial","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 \u0026hellip;\nTip 2 \u0026hellip;","tags":null,"title":"Example Page","type":"docs"},{"authors":["**R\u0026uuml;eger, S**","McDaid, A","Kutalik, Z"],"categories":null,"content":"","date":1535752800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535752800,"objectID":"b4edcfb7d66f21452231eaaa94f14806","permalink":"https://sinarueeger.github.io/publication/plosgen-2018-ssimp-application/","publishdate":"2018-09-01T00:00:00+02:00","relpermalink":"/publication/plosgen-2018-ssimp-application/","section":"publication","summary":"","tags":[""],"title":"Evaluation and application of summary statistic imputation to discover new height-associated loci","type":"publication"},{"authors":["**R\u0026uuml;eger, S**","McDaid, A","Kutalik, Z"],"categories":null,"content":"","date":1535752800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535752800,"objectID":"e364d4763049b6bb668db3250aa8d3c5","permalink":"https://sinarueeger.github.io/publication/biorxiv-2018-ssimp-method/","publishdate":"2018-09-01T00:00:00+02:00","relpermalink":"/publication/biorxiv-2018-ssimp-method/","section":"publication","summary":"","tags":[""],"title":"Improved imputation of summary statistics for admixed populations","type":"publication"},{"authors":null,"categories":null,"content":"   Goal Getting it done 1. Get summary statistics Visualising associations Identify genomic region with lowest P-value  2. Extracting annotation biomaRt Learning resources Using biomaRt Quick d-tour: assembly GRCh37 or GRCh38? Extracting gene name for one SNP Extracting gene names for genomic region  3. Combining summary statistics and annotation Wouldn’t it be nice… Source   In the world of genome-wide association studies (GWAS) we often get a list of genetic markers (SNPs) that seem for some reason relevant for a particular outcome. At the same time, we have little knowledge about these genetic variants that come in cryptic combinations of characters and numbers.\nFor example:\n We might get asked how frequent the SNP rs1421085 is in a range of populations.  We need to extract all known SNPs that are within 1 Mb of rs1421085.  A genomic region turns out to be highly relevant for some disease and we want to know all genes contained in that genomic region.  Unless you sit on lots of genetic data, the list of SNPs come from a summarised form. Minimally, these summary statistic datasets contain the SNP identifier (SNPNAME), the effect size (beta) and the standard error (se). Sometimes the position (POS) and chromosome (CHR) is provided instead of the SNP identifier, and sometimes both are available. Then there is usually other information coming from the study data, for example the allele frequency in the study  this is shown on the LHS in table below. However, hardly ever do the datasets contain annotation, such as the gene where the SNP resides, the phenotypes it is associated with or the minor allele frequency (MAF) in a certain population  this is illustrated in the green colored part in table below.\n  GWAS summary statistics dataset   Annotation     CHR  POS  SNPNAME  REF  ALT  beta  se  Gene  Linked phenotype  Global MAF      7  75163169  rs1167827  A  G  0.028  0.0032  HIP1  BMI  0.4720450    12  122781897  rs11057405  G  A  -0.021  0.0037  CLIP1  BMI  0.0327476    10  114758349  rs7903146  C  T  -0.031  0.0023  TCF7L2  BMI  0.2278350    1  49589847  rs657452  A  G  -0.015  0.0025  AGBL4  BMI  0.4532750    1  49589847  rs657452  A  G  -0.015  0.0025  AC099788.1  BMI  0.4532750     This makes sense. Genetic data from cohorts will be used for years and won’t change, but the annotation will change over the years. Take the chromosomal position of SNPs, that changes with every new human genome reference assembley.\nTo get our hands on annotation, we need to consult external databases that are - lucky us! - public. But first, let us define what we want to see at the end of the blogpost.\nGoal For this blogpost, we keep it simple and only focus on the genes contained in a genomic region, but this can be easily extended to any other annotation available in databases.\nIn the illustration below1, we want to know the gene starting and end positions around one particular gene region to create an informative locuszoom plot.\n  In this case, we want to visualise the GWAS P-value (-log10(P-value)) of a genomic region (with each point representing a SNP), with the corresponding genes at the bottom. This is similar to a plot done with LocusZoom, a tool that takes summary statistics as input and outputs a pretty graph for a desired genomic region, including gene annotation, LD information and more.     Getting it done There are currently more than 10 Mio SNPs known, and knowing their functions and genes by heart would equal to some super power. Which is why we 2 public databases, such as dbSNP and ensembl3.\nWhat we like even more, is, to make our analyses reproducible and automate annotation and lookups.\n In this blogpost, I will show how to zoom into GWAS results and annotate the plot based on the information about that genomic region using R. Here is the plan:\nGet summary statistics Extract annotation Combine summary statistics and annotation  Before tackling the first item, we want to have all R-packages installed \u0026amp; ready to use:\n## Packages needed to run code ## ---------------------------- # install.packages(\u0026quot;dplyr\u0026quot;) ## data manipulation # install.packages(\u0026quot;data.table\u0026quot;) ## read data, fast! # install.packages(\u0026quot;forcats\u0026quot;) ## dealing with factors # install.packages(\u0026quot;ggplot2\u0026quot;) ## dataviz # install.packages(\u0026quot;magrittr\u0026quot;) ## piping # install.packages(\u0026quot;metafolio\u0026quot;) ## colorpalette # install.packages(\u0026quot;skimr\u0026quot;) ## summarising data # install.packages(\u0026quot;qqman\u0026quot;) ## Manhattan plot # install.packages(\u0026quot;patchwork\u0026quot;) ## assembling plots # source(\u0026quot;https://bioconductor.org/biocLite.R\u0026quot;) # biocLite(\u0026quot;biomaRt\u0026quot;) ## annotation ## Optional packages for Rmd ## -------------------------- # install.packages(\u0026quot;kableExtra\u0026quot;) ## making pretty tables # install.packages(\u0026quot;devtools\u0026quot;) # devtools::install_github(\u0026quot;hadley/emo\u0026quot;) ## emojis # devtools::install_github(\u0026quot;ropenscilabs/icon\u0026quot;) ## icons  1. Get summary statistics First, we need some GWAS summary statistics.\nThere are lots of resources for publicly available GWAS summary statistics.\nWe will look at BMI, because it can be accessed easily4 and because it is fairly small for a genomic dataset. The data is from the Genetic Investigation of ANthropometric Traits (GIANT) consortium. You can download the dataset5 here or load it directly into R.\n## Data Source URL url \u0026lt;- \u0026quot;https://portals.broadinstitute.org/collaboration/giant/images/2/21/BMI_All_ancestry.fmt.gzip\u0026quot; #url \u0026lt;- \u0026quot;jenger.riken.jp/1analysisresult_qtl_download/All_2017_BMI_BBJ_autosome.txt.gz\u0026quot; ## Import BMI summary statistics dat.bmi \u0026lt;- read_tsv(file = url) ## ## taking too long, let\u0026#39;s use fread instead. dat.bmi \u0026lt;- data.table::fread(url, verbose = FALSE) I added verbose = FALSE because it will complain that there is an unexpected character in column 1, which appears to be numerical. This is because chromosome X will only appear towards the end of the dataset.\nNext, we rename some columns to something more conventional.\n## Rename some columns dat.bmi \u0026lt;- dat.bmi %\u0026gt;% rename(SNP = SNPNAME, P = Pvalue) Now, let’s look at the data with the skimr package.\nskimr::skim(dat.bmi) ## Skim summary statistics ## n obs: 246328 ## n variables: 10 ## ## ── Variable type:character ───────────────────────────────────────────────────────────────────────────────────────── ## variable missing complete n min max empty n_unique ## ALT 0 246328 246328 1 1 0 4 ## CHR 0 246328 246328 1 2 0 23 ## ExAC_MAF 0 246328 246328 1 325 0 51423 ## GMAF 0 246328 246328 1 17 0 9964 ## REF 0 246328 246328 1 1 0 4 ## SNP 0 246328 246328 1 11 0 243206 ## ## ── Variable type:integer ─────────────────────────────────────────────────────────────────────────────────────────── ## variable missing complete n mean sd p0 p25 p50 ## POS 0 246328 246328 7.6e+07 5.7e+07 11885 3.2e+07 6.1e+07 ## p75 p100 hist ## 1.1e+08 2.5e+08 ▇▇▅▅▃▂▁▁ ## ## ── Variable type:numeric ─────────────────────────────────────────────────────────────────────────────────────────── ## variable missing complete n mean sd p0 p25 ## beta 977 245351 246328 0.00051 0.13 -3.2 -0.032 ## P 977 245351 246328 0.48 0.3 8.6e-269 0.21 ## se 0 246328 246328 Inf NaN 0.002 0.023 ## p50 p75 p100 hist ## -0.00017 0.031 3.2 ▁▁▁▇▇▁▁▁ ## 0.47 0.73 1 ▇▇▆▆▆▆▆▆ ## 0.059 0.11 Inf ▇▁▁▁▁▁▁▁ The reference allele (REF), alternative allele (ALT), SNP identifier (SNP) and chromosome (CHR) are characters. There are four unique values for ALT and REF: A, C, G, T, and 23 unique values for CHR - seems about right. The two columns with the minor allele frequencies measured in GIANT and ExAC datasets (GMAF, ExAC_MAF) are characters too, because the allele is concatenated. The chromosomal position (POS) is an integer. Then there is the actual association of each SNP with BMI (beta, se, P).\nThis dataset has 246328 rows and 10 columns. What if we want to visualise this all at once? In particularly, we are interested if there are ANY associations between the genetic markers and BMI. The mini P distribution in the skimr output does not reveal much.\nVisualising associations Visualising all associations at once can be done with a Manhattan plot, where the x-axis represents chromosomeCHR and the chromosomal position POS, and the y-axis the -log10(P)-value. Let’s use the R-package qqman6 for that.\nqqman::manhattan(dat.bmi %\u0026gt;% mutate(CHR = as.numeric(as.character(fct_recode(CHR, \u0026quot;23\u0026quot; = \u0026quot;X\u0026quot;)))) %\u0026gt;% filter(-log10(P)\u0026gt;1), chr=\u0026quot;CHR\u0026quot;, bp=\u0026quot;POS\u0026quot;, snp=\u0026quot;SNP\u0026quot;, p=\u0026quot;P\u0026quot;, suggestiveline =FALSE, genomewideline = FALSE, chrlabs = c(1:22, \u0026quot;X\u0026quot;), cex = 0.4) We can spot immediately, that there are loads of SNPs with P-values smaller than \\(10^{-100}\\) (sample size was around 700K).\nOf course, there are many other solutions to spot real associations, but this is not the point of this blogpost ;-).\n Identify genomic region with lowest P-value Now that we know that there are lots of genetic markers associated with BMI, we want to look at a specific genomic region and figure out what genes it contains. For illustrative purposes, we pick the genomic region with the lowest P-value.\ndat.bmi.sel \u0026lt;- dat.bmi %\u0026gt;% slice(which.min(P)) dat.bmi.sel ## CHR POS REF ALT SNP GMAF ExAC_MAF beta se P ## 1 16 53800954 T C rs1421085 C:0.2286 - 0.078 0.0022 8.6e-269 SNP identifier rs1421085 that has the lowest P-value (\\(P = 8.6\\times 10^{-269}\\)).\nNow we can visualise the summary statistics of that genomic region (\\(\\pm 500 \\cdot 10^{3}\\)).\nrange \u0026lt;- 5e+05 sel.chr \u0026lt;- dat.bmi.sel$CHR sel.pos \u0026lt;- dat.bmi.sel$POS dat.bmi.sel.region \u0026lt;- dat.bmi %\u0026gt;% filter(CHR == sel.chr, between(POS, sel.pos - range, sel.pos + range)) p1 \u0026lt;- ggplot(data = dat.bmi.sel.region) + geom_point(aes(POS, -log10(P)), shape = 1) + labs(title = \u0026quot;Locuszoomplot for BMI GWAS\u0026quot;, subtitle = paste(\u0026quot;Summary statistics for chromosome\u0026quot;, sel.chr, \u0026quot;from\u0026quot;, format((sel.pos - range), big.mark = \u0026quot;\u0026#39;\u0026quot;), \u0026quot;to\u0026quot;, format((sel.pos + range), big.mark = \u0026quot;\u0026#39;\u0026quot;), \u0026quot;bp\u0026quot;), caption = paste(\u0026quot;Data source:\u0026quot;, url)) print(p1) Next, we want to know if rs1421085 is part of a gene, and if yes, which one.\n  2. Extracting annotation biomaRt Thankfully, there is an R-package called biomaRt that can do this for us.\nI have only come across this package a few weeks ago, so I apologise in advance that I won’t make full use of all the features that the package offers.\n biomaRt should not to be confused with biomartr. biomartr is an rOpenSci package by Hajk-Georg Drost. I needed this tweet  to realise that these were two separate, yet related R-packages.\nDid you ever want to reproducibly retrieve thousands of genomes across the tree of life using only one R command? Then have a look at the new version of biomartr which is on its way to CRAN! https://t.co/kWF5XCoGhj #bioinformatics #rstats #Genomics pic.twitter.com/EZHJP0n1f9 — Hajk-Georg Drost (@HajkDrost) June 28, 2018   So far, I did not fully grasp the benefits of biomartr compared to biomaRt for annotation of human data. But I will definitely look more into it.\nI also got a tip from Marianna Foos to check out rsnps, an R-package dealing with SNP annotation.\n Learning resources I used mainly two sources to learn what I wanted to do:\n Vignette of biomaRt on Bioconductor7. This question on StackOverflow.   Using biomaRt First, we need to load the biomaRt package from Bioconductor.\nlibrary(biomaRt)  Next we specify which database to use. You can use the functions listMart(), listEnsembl() and listDatasets() to select from the right biomart and dataset. We will need to extract SNPs, hence biomart = \"snp\".\nsnp.ensembl \u0026lt;- useEnsembl(biomart = \u0026quot;snp\u0026quot;, dataset = \u0026quot;hsapiens_snp\u0026quot;) class(snp.ensembl) ## [1] \u0026quot;Mart\u0026quot; ## attr(,\u0026quot;package\u0026quot;) ## [1] \u0026quot;biomaRt\u0026quot; # other ways of selecting the mart snp.mart \u0026lt;- useMart(biomart = # \u0026#39;ENSEMBL_MART_SNP\u0026#39;, dataset=\u0026#39;hsapiens_snp\u0026#39;) # gene.mart \u0026lt;- useMart(\u0026#39;ensembl\u0026#39;, dataset=\u0026#39;hsapiens_gene_ensembl\u0026#39;) Last, we extract the gene id to which our SNP belongs using the function getBM(). Along with that we also extract other information, like the minor allele frequency minor_allele_freq. To check which attributes and filters are available, run listAttributes(snp.ensembl) and listFilters(snp.ensembl).\nout.bm \u0026lt;- getBM( attributes = c(\u0026quot;ensembl_gene_stable_id\u0026quot;, \u0026quot;refsnp_id\u0026quot;, \u0026quot;chr_name\u0026quot;, \u0026quot;chrom_start\u0026quot;, \u0026quot;chrom_end\u0026quot;, \u0026quot;minor_allele\u0026quot;, \u0026quot;minor_allele_freq\u0026quot;), # \u0026quot;ensembl_transcript_stable_id\u0026quot;, # \u0026quot;consequence_type_tv\u0026quot;), filters = \u0026quot;snp_filter\u0026quot;, values = \u0026quot;rs1421085\u0026quot;,#dat.bmi.sel$SNP, mart = snp.ensembl) This gives us - as chosen in attributes - the gene identifier, the SNP identifier, the chromosome name, chromosomal position (start + end), minor allele and minor allele frequency. The output in out.bm corresponds to this webpage entry on the ensembl webpage.\nout.bm ## ensembl_gene_stable_id refsnp_id chr_name chrom_start chrom_end ## 1 ENSG00000140718 rs1421085 16 53767042 53767042 ## minor_allele minor_allele_freq ## 1 C 0.228634  Quick d-tour: assembly GRCh37 or GRCh38? Before getting the gene names, we want to check if the position in the dataset are from assembly GRCh37 or GRCh38. This is a handy thing, because oftentimes only SNP identifiers are reported. Or SNP identifiers are reported, but with positions on a different assembly.\nifelse(sel.pos == out.bm$chrom_start, \u0026quot;\\u2713: same assembley (GRCh38)\u0026quot;, \u0026quot;\\u2717: not the same assembley\u0026quot;) ## [1] \u0026quot;✗: not the same assembley\u0026quot; The position is not matching, because the databases that we are looking at is based on the most recent human assembly GRCh38, but the BMI summary statistics dataset is based on human assembly GRCh37. The command listEnsemblArchives() will list you the URLs needed to get access to an archived assembly. So let’s pull out the archived GRCh37 version with the argument host = 'http://grch37.ensembl.org'.\nsnp.ensembl.grch37 \u0026lt;- useMart(host=\u0026#39;http://grch37.ensembl.org\u0026#39;, biomart=\u0026#39;ENSEMBL_MART_SNP\u0026#39;, dataset=\u0026#39;hsapiens_snp\u0026#39;) out.bm.grch37 \u0026lt;- getBM( attributes = c(\u0026#39;ensembl_gene_stable_id\u0026#39;, \u0026#39;refsnp_id\u0026#39;, \u0026#39;chr_name\u0026#39;, \u0026#39;chrom_start\u0026#39;, \u0026#39;chrom_end\u0026#39;, \u0026#39;minor_allele\u0026#39;, \u0026#39;minor_allele_freq\u0026#39;), filters = \u0026#39;snp_filter\u0026#39;, values = dat.bmi.sel$SNP, mart = snp.ensembl.grch37 ) out.bm.grch37 ## ensembl_gene_stable_id refsnp_id chr_name chrom_start chrom_end ## 1 ENSG00000140718 rs1421085 16 53800954 53800954 ## minor_allele minor_allele_freq ## 1 C 0.228634 Let’s check again.\nifelse(sel.pos == out.bm.grch37$chrom_start, \u0026quot;\\u2713: same assembley (grch37)\u0026quot;, \u0026quot;\\u2717: not the same assembley\u0026quot;) ## [1] \u0026quot;✓: same assembley (grch37)\u0026quot; Flavia Hodel pointed out that adding the argument GRCh = 37 works too! That’s handy argument (but limited to GRCh versions 37 and 38).\nsnp.ensembl.grch37.alt \u0026lt;- useEnsembl(biomart = \u0026quot;snp\u0026quot;, dataset = \u0026quot;hsapiens_snp\u0026quot;, GRCh = 37) out.bm.grch37 \u0026lt;- getBM( attributes = c(\u0026#39;ensembl_gene_stable_id\u0026#39;, \u0026#39;refsnp_id\u0026#39;, \u0026#39;chr_name\u0026#39;, \u0026#39;chrom_start\u0026#39;, \u0026#39;chrom_end\u0026#39;, \u0026#39;minor_allele\u0026#39;, \u0026#39;minor_allele_freq\u0026#39;), filters = \u0026#39;snp_filter\u0026#39;, values = dat.bmi.sel$SNP, mart = snp.ensembl.grch37.alt ) out.bm.grch37 ## ensembl_gene_stable_id refsnp_id chr_name chrom_start chrom_end ## 1 ENSG00000140718 rs1421085 16 53800954 53800954 ## minor_allele minor_allele_freq ## 1 C 0.228634 ifelse(sel.pos == out.bm.grch37$chrom_start, \u0026quot;\\u2713: same assembley (grch37)\u0026quot;, \u0026quot;\\u2717: not the same assembley\u0026quot;) ## [1] \u0026quot;✓: same assembley (grch37)\u0026quot;  Extracting gene name for one SNP Next, we want to get the gene name where rs1421085 falls into.\nLet’s check which attributes contain the string gene.\nlistAttributes(snp.ensembl) %\u0026gt;% slice(str_which(name, \u0026quot;gene\u0026quot;))  ## name description page ## 1 associated_gene Associated gene with phenotype snp ## 2 ensembl_gene_stable_id Gene stable ID snp Now use ensembl_gene_stable_id and associated_gene as additional attributes.\n## extract gene ## ---------- out.bm.snp2gene \u0026lt;- getBM( attributes = c(\u0026#39;refsnp_id\u0026#39;, \u0026#39;allele\u0026#39;, \u0026#39;chrom_start\u0026#39;, \u0026#39;chr_name\u0026#39;, \u0026#39;ensembl_gene_stable_id\u0026#39;), filters = c(\u0026#39;snp_filter\u0026#39;), values = dat.bmi.sel$SNP, mart = snp.ensembl) out.bm.snp2gene ## refsnp_id allele chrom_start chr_name ensembl_gene_stable_id ## 1 rs1421085 T/C 53767042 16 ENSG00000140718 ## Attribute `associated_gene` is `Associated gene with phenotype`. ## Extract string ## ---------- gene.ensembl \u0026lt;- useEnsembl(biomart = \u0026quot;ensembl\u0026quot;, dataset = \u0026quot;hsapiens_gene_ensembl\u0026quot;, GRCh = 37) # we will need an additional mart for genes ## because we are using positions from GRCh = 37 in a next query, we need to pass that information on. out.bm.gene \u0026lt;- getBM(attributes = c(\u0026#39;external_gene_name\u0026#39;), filters = c(\u0026#39;ensembl_gene_id\u0026#39;), values = unique(out.bm.snp2gene$ensembl_gene_stable_id), mart = gene.ensembl) out.bm.gene ## external_gene_name ## 1 FTO The gene that contains SNP rs1421085 is called FTO.\n Extracting gene names for genomic region So now we know that rs1421085 is part of FTO. But where does FTO start and end? And what are the genes nearby? For this purpose, we want to visualise the summary statistics of the full genomic region (\\(\\pm 250 \\cdot 10^3\\) Mb). We just recycle the previous code, but instead of providing a SNP-id, we provide the chromosome, the start and the end position.\nout.bm.genes.region \u0026lt;- getBM( attributes = c(\u0026#39;start_position\u0026#39;,\u0026#39;end_position\u0026#39;,\u0026#39;ensembl_gene_id\u0026#39;,\u0026#39;external_gene_name\u0026#39;, \u0026#39;gene_biotype\u0026#39;), filters = c(\u0026#39;chromosome_name\u0026#39;,\u0026#39;start\u0026#39;,\u0026#39;end\u0026#39;), values = list(sel.chr, sel.pos - range, sel.pos + range), mart = gene.ensembl) head(out.bm.genes.region) ## start_position end_position ensembl_gene_id external_gene_name ## 1 53088945 53363062 ENSG00000177200 CHD9 ## 2 53332136 53333704 ENSG00000261056 RP11-454F8.2 ## 3 53368474 53368576 ENSG00000238645 snoU13 ## 4 53371365 53371483 ENSG00000202193 RNA5SP427 ## 5 53395931 53397590 ENSG00000259962 RP11-44F14.4 ## 6 53398894 53406995 ENSG00000260078 RP11-44F14.1 ## gene_biotype ## 1 protein_coding ## 2 pseudogene ## 3 snoRNA ## 4 rRNA ## 5 pseudogene ## 6 pseudogene We can plot out.bm.genes.region with a linerange plot, where each horizontal line represents one gene.\n## rank gene names according to start position out.bm.genes.region \u0026lt;- out.bm.genes.region %\u0026gt;% mutate(external_gene_name = fct_reorder(external_gene_name, start_position, .desc = TRUE)) ## plot ggplot(data = out.bm.genes.region) + geom_linerange(aes(x = external_gene_name, ymin = start_position, ymax = end_position)) + coord_flip() + ylab(\u0026quot;\u0026quot;) Let’s try to make that pretty. We can group the genes by gene_biotype and colour them accordingly. And we move the protein-coding genes to the top row and color it black.\n## define plot range for x-axis plot.range \u0026lt;- c(min(sel.pos - range, out.bm.genes.region$start_position), max(sel.pos + range, out.bm.genes.region$end_position)) ## rank gene_biotype label out.bm.genes.region \u0026lt;- out.bm.genes.region %\u0026gt;% mutate(gene_biotype_fac = fct_relevel(as.factor(gene_biotype), \u0026quot;protein_coding\u0026quot;), external_gene_name = fct_reorder2(external_gene_name, start_position, gene_biotype_fac, .desc = TRUE)) ## plot p2 \u0026lt;- ggplot(data = out.bm.genes.region) + geom_linerange(aes(x = external_gene_name, ymin = start_position, ymax = end_position, colour = gene_biotype_fac, group = gene_biotype_fac)) + coord_flip() + ylab(\u0026quot;\u0026quot;) + ylim(plot.range) + geom_text(aes(x = external_gene_name, y = start_position, label = external_gene_name, colour = gene_biotype_fac), fontface = 2, alpha = I(0.7), hjust = \u0026quot;right\u0026quot;, size= 2.5) + labs(title = \u0026quot;\u0026quot;, subtitle = paste0(\u0026quot;Genes\u0026quot;), caption = paste0(\u0026quot;Data source: \u0026quot;, gene.ensembl@host, \u0026quot; + Data set: \u0026quot;, gene.ensembl@dataset), color = \u0026quot;Gene Biotype\u0026quot;) + theme(axis.title.y=element_blank(), axis.text.y=element_blank(), axis.ticks.y=element_blank(), strip.text.y = element_text(angle = 0), legend.position=\u0026quot;bottom\u0026quot;, panel.grid.major.y = element_blank()) + expand_limits(y=c(-1, 1)) + scale_color_manual(values = c(\u0026quot;black\u0026quot;, metafolio::gg_color_hue(nlevels(out.bm.genes.region$gene_biotype_fac)-1))) ## hack to have 11 colors, but probably merging some gene biotype groups could make sense too. ## consider colorblindr::palette_OkabeIto_black print(p2) There are some short genes starting with AC and LINCO. We can check what they are and/or consult a biologist.\n  3. Combining summary statistics and annotation Now we are ready to combine plot p1 and p2.\nlibrary(patchwork) p1b \u0026lt;- p1 + xlab(\u0026quot;\u0026quot;) + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) + xlim(plot.range) p1b + p2 + plot_layout(ncol = 1, heights = c(6, 6)) Having both plots combined, we can spot that the are 6 protein-coding genes in the region. But the P-value peak is located in gene FTO.\nIf this were work done for a real project, this would now be the time to get back to domain experts, discuss the results and figure out what other annotation they need8.\n Wouldn’t it be nice…  … to polish that plot even more? For starters, the colour code is not ideal… … to add information about the correlation between SNPs, like in LocusZoom plots? … or have an interactive plot9: hovering over the SNP points would light up the corresponding genes or give some other information, like the allele frequency.  Totally 😉 Seems like great material for future blogposts!\n Source  The R Markdown file is here. Some more biomaRt code snippets are in a gist.  If you know another R-package to solve a similar problem or have feedback, you can comment below 👇.\n  Thanks to Maëlle Salmon you get a real plot here instead of a blurry hand drawing 😉 She gave lots of feedback on my first version - much appreciated!↩\n Awesome icons in R?      checkout these instructions by Mitchell O’Hara-Wild on the rOpenSci webpage.↩\n Thanks to my colleagues with biology background for explaining me the differences between these databases and what a biomart is!↩\n Initially, I wanted to use data from two recent studies by the Psychiatric Genomics Consortium (PGC) on schizophrenia (SCZ) and bipoloar disorder (BD), as well as Major depressive disorder (MDD). Like most consortia, PGC provides summary statistics that can be downloaded. However, before downloading anything, the user needs to acknowledge and agree to a list of conditions - which I think is an excellent approach! - therefore we cannot directly load it into R.↩\n Data source: Yengo et al. (2018).↩\n A guide to crafting Manhattan plots by Yan Holtz for the R graph gallery↩\n I recently listened to a podcast by Saskia Freytag and NJ Tierney where they talk about the differences between CRAN and Bioconductor (there are many!). The podcast is called Credibly Curious.↩\n +1 for reproducibility!↩\n Liza Darrous pointed out the interactive Manhattan R function manhanttanly.↩\n   ","date":1532908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532908800,"objectID":"878cf620f59faea12ff979b4a1095038","permalink":"https://sinarueeger.github.io/post/locuszoomplot/","publishdate":"2018-07-30T00:00:00Z","relpermalink":"/post/locuszoomplot/","section":"post","summary":"Goal Getting it done 1. Get summary statistics Visualising associations Identify genomic region with lowest P-value  2. Extracting annotation biomaRt Learning resources Using biomaRt Quick d-tour: assembly GRCh37 or GRCh38? Extracting gene name for one SNP Extracting gene names for genomic region  3. Combining summary statistics and annotation Wouldn’t it be nice… Source   In the world of genome-wide association studies (GWAS) we often get a list of genetic markers (SNPs) that seem for some reason relevant for a particular outcome.","tags":["statistical genetics","R","data visualisation"],"title":"Locuszoom plot of GWAS summary statistics","type":"post"},{"authors":null,"categories":null,"content":" This is a brief write-up of my satRdays Cardiff experience.\nFirst - what is a satRday?\nIt is an awesome concept: attending an R conference organised by a local RUG on a Saturday.\nThe programme in Cardiff had parallel sessions - tough decision-making to pick between promising talks!\ndplyr workshop Kathrine Tansey kept us busy with a workshop on dplyr in the morning.\n💻 rstudio-cloud project\nPackaging workshop Heather Turner upgraded us on packaging.\n💡 useful tips and workflow! Eager to apply what I learned.\n💻 rstudio-cloud project\n➡️ Slides\nIntroduction to tidytext Textmining with Nujcharee (เป็ด), applied to #metoo twitter data:\nMy slide on Introduction to Tidytext https://t.co/XOiEiedNjN @satRdays_org #rstats\n\u0026mdash; Nujcharee (เป็ด) (@Nujcharee) June 23, 2018 Package reviews with rOpenSci Maëlle Salmon presented the review process of rOpenSci and then reviewed the review process using the force of textmining.\n💡 Rigorous, but friendly reviewing process at rOpenSci.\nMore info on submitting a package for review here.\n➡️ Slides\nAirtable \u0026amp; R Amy McDougall presented airtable (💡!) and the R interface airtabler.\nAmy wrote a blogpost on this topic too (which I found through Locke Data\u0026rsquo;s write up here).\n➡️ Slides\nLightening talks Counting and weighing Penguins Philipp Boersch-Supan telling us about the challenges of counting penguins (and apparently Rcpp helps).\nIntegrating command-line tools with R Erle Holgersen: embrace the system() function for command-line snippets in R.\nFor example:\nls.directory \u0026lt;- system(\u0026quot;ls -all\u0026quot;, intern = TRUE)  💡 intern = TRUE is my new friend!\nOther tips: - use the command line functionality in data.table::fread(\u0026quot;\u0026quot;) - make use of tempfile()\ngit in five Steph Locke gave git in a nutshell.\n💡 Recommendation: use GitKraken as a GUI client.\ntidy eval Nic Crane explaining the basics of tidy eval and when it is needed (💡 functions!).\nA simple Bayesian workflow Paul Robinson presented his Bioconductor package dealing with proteins.\n➡️ Slides\nR-Forwards and R-Ladies Remote Heather Turner presented two #rstats related initiatives.\nR Forwards is an initiative to widen the participation of under-represented groups ➡️ looking for volunteers that take on tasks.\nR-Ladies remote chapter: has monthly coffee breaks on slack!\nFinal remarks 👏 Kudos to the organisers! They paid lots of attention to details and did an awesome job in making everyone feel welcome!\n✍️ Mental note to self: I should probably learn how to take pics at the right time + live tweet 😉\nFurther information 📁 Slides repo.\n📘 Check out Maëlle\u0026rsquo;s blogpost on Storrrify #satRdayCDF 2018.\n📘 Loads of info from the Locke Data team members.\n#satRdayCDF on Twitter.\n⏭️ Next satRday is on September 1 2018 in Amsterdam.\n📅 Check all upcoming events.\nAlso 👇\nIf you would like a satRday near you, why not run one?\nHere\u0026#39;s what you need to know to decide if it\u0026#39;s right for you https://t.co/Szy7AMB3rF\n\u0026mdash; satRdays (@satRdays_org) June 26, 2018 ","date":1530662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530662400,"objectID":"7af74600ae0107467cf199df6c223a76","permalink":"https://sinarueeger.github.io/post/satrdaycardiff/","publishdate":"2018-07-04T00:00:00Z","relpermalink":"/post/satrdaycardiff/","section":"post","summary":"This is a brief write-up of my satRdays Cardiff experience.\nFirst - what is a satRday?\nIt is an awesome concept: attending an R conference organised by a local RUG on a Saturday.\nThe programme in Cardiff had parallel sessions - tough decision-making to pick between promising talks!\ndplyr workshop Kathrine Tansey kept us busy with a workshop on dplyr in the morning.\n💻 rstudio-cloud project\nPackaging workshop Heather Turner upgraded us on packaging.","tags":["conference","R","satRday","rOpenSci","package","dplyr"],"title":"satRday Cardiff 2018","type":"post"},{"authors":null,"categories":null,"content":"I work (broadly speaking) in epidemiology. Within collaborations we often have to share sensitive data across institutions and are therefore likely to not share IT facilities. But the most often used options - bare e-mail or file hosting - are not secure, as they both work via a server that could potentially be exposed.\nThere are a handful of secure options around (ProtonMail or keybase.io, both working via encryption), but for those that trust open source projects the most and are familiar with a terminal I have written some basic instructions for asymmetric GPG encryption.\nI should say that I am not an encryption expert at all. But, although there is a lot of talk about data protection, I never came across a compact, easy-to-follow instruction for the sender of the document and the recipient, valid for all three operating systems (Linux, Mac, Windows). Therefore, I tried to write one, mainly for myself and collaborators. Feedback is appreciated!\n ","date":1523644859,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523644859,"objectID":"dbca7dfcf69c05fd04ce13b346a6aeb2","permalink":"https://sinarueeger.github.io/post/2018-04-04-encryption-of-files/","publishdate":"2018-04-13T20:40:59+02:00","relpermalink":"/post/2018-04-04-encryption-of-files/","section":"post","summary":"I work (broadly speaking) in epidemiology. Within collaborations we often have to share sensitive data across institutions and are therefore likely to not share IT facilities. But the most often used options - bare e-mail or file hosting - are not secure, as they both work via a server that could potentially be exposed.\nThere are a handful of secure options around (ProtonMail or keybase.io, both working via encryption), but for those that trust open source projects the most and are familiar with a terminal I have written some basic instructions for asymmetric GPG encryption.","tags":["encryption","best practices","workflow"],"title":"Getting started with encryption of documents","type":"post"},{"authors":["**R\u0026uuml;eger, S**","Bochud, P-Y","Dufour, J-F","M\u0026uuml;llhaupt, B","Semela, D","Heim, M H","Moradpour, D","Cerny, A","Malinverni, R","Booth, D R","Suppiah, V","George, J","Argiro, L","Halfon, P","Bourli\u0026egrave;re, M","Talal, A H","Jacobson, I M","Patin, E","Nalpas, B","Poynard, T","Pol, S","Abel, L","Kutalik, Z","Negro, F"],"categories":null,"content":"","date":1441058400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441058400,"objectID":"8089d020d4b95ead47a18ea77aaa9b9a","permalink":"https://sinarueeger.github.io/publication/gut-2015-fibrosis/","publishdate":"2015-09-01T00:00:00+02:00","relpermalink":"/publication/gut-2015-fibrosis/","section":"publication","summary":"","tags":[],"title":"Impact of common risk factors of fibrosis progression in chronic hepatitis C","type":"publication"}]
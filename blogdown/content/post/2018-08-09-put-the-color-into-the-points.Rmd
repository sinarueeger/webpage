---
title: 'Put the color into the points'
date: '2018-08-09'
slug: add-ld
categories: 
  - statgen
  - R
  - data visualisation
tags: 
  - statgen
  - R
  - data visualisation
  - R
  - ggplot2
description: ''
draft: true
header:
  caption: ''
  image: ''
---

One of the most painful and weirdly difficult things to do in my field is to calculate correlations from a genome reference panel.  
And correlations have to be computed *ALL THE TIME*. 

I have this foggy memory that I once loaded one xx MB into R, on a server, on the master, and then I applied the correlation function not accounting for the NAs. But I might have been dreaming this though - one of my biggest nightmares is to kill an HPC.

After all, R is a software for statistical computing, so why not calculating the correlation - THE statistics - in R? 
For starters, it requires to have the data somewhere stored. For 1000 genomes reference panel you need xxx MB. 
Second, R "handles large datasets badly". I put that in quotes, because I have no idea how to say that otherwise and I also have no idea why. It just seems super inefficient. If you need to import a large file, think twice, or tweak it. For example, for correlations this would mean, only importing a range of columns. But reference panels typically come in vcf format, so good luck with that. 
Lastly, try to calculate a 1000 by 1000 correlation matrix in R. Uses loads of memory! Even if you do ... 

There are a couple of options out there: 
1. have 1000 genomes stored somewhere, use some special tool like [emeraLD](https://github.com/statgen/emeraLD/blob/master/emeraLD2R.r) (input vcf files), [plink](https://www.cog-genomics.org/plink/1.9/ld) or [LDSTORE](http://www.christianbenner.com/#ldstore) (input bgen or binary plink), all requiring computing space and ... 
2. precompute matrices, store and access them (requires HPC)
3. use an API that does all this for you. 

For example: the [locuszoom](https://genome.sph.umich.edu/wiki/LocusZoom_Standalone#Download) standalone function comes with all reference panels needed to calculate LD. This has advantages (always up to date, reproducible, independent) and disadvantages (BIG! MB)


- [**emeraLD**](https://github.com/statgen/emeraLD)
  - ðŸ”º LD
  - Input file formats: VCF
  
- -[QCTOOL](http://www.well.ox.ac.uk/~gav/qctool_v2/))
   ðŸ”º LD
  - Input file formats: bgen, binary plink (no vcf, meaning, reference panels in vcf format have to be transformed first into a bgen file with [Q## Reference panels

Before doing this, lets 


## Quick but incomplete solution: `rsnps`

A perfect solution would be to use the function `ld_search` from R package [`rsnps`](https://cran.r-project.org/web/packages/rsnps/vignettes/rsnps_vignette.html). It has arguments to choose the reference panel, the population, the distance from the focal SNP... The problem is, that it only uses old reference panels (HapMap and 1KG-phase1). That means, some newer reference panel populations are left out. Besides, for some reason `ld_search` returns me an error. 


```{r, rsnps-calc-ld}
#devtools::install_github("ropensci/rsnps")
library(rsnps)
ld_search("rs12286929") ## not working, and if, only working for phase1
```

## The other incomplete option: using `https://rest.ensembl.org`

Let's quickly repeat what our goal is:

Extract the correlation between SNPs of 1000 Genomes reference panel 
- without downloading any data,
- fairly quick and
- in R?

```{r, example}
snp <- "rs199141"
sm <- ncbi_snp_summary(snp) %>% separate(chrpos, c("chr", "pos"))
sel.chr <- sm$chr
sel.pos <- 	as.numeric(sm$pos)
range <- 500e3 ## in bp
range.kb <- range/1e3
```

### LD between SNP1 and region


```{r, calc-ld-SNP-region}

library(httr)
library(jsonlite)
library(xml2)

## FROM: https://rest.ensembl.org/documentation/info/ld_id_get
server <- "https://rest.ensembl.org"
ext <- glue::glue("/ld/human/{snp}/1000GENOMES:phase_3:PUR?")#defautl an
## Window size in kb. The maximum allowed value for the window size is 500 kb. LD is computed for the given variant and all variants that are located within the specified window.

r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
stop_for_status(r)
LD.SNP.region <- as_tibble(fromJSON(toJSON(content(r)))) %>% unnest() %>% mutate(r2 = as.numeric(r2))

```

### Calculate LD matrix

```{r, calc-ld-region, cache = TRUE}
## https://rest.ensembl.org/documentation/info/ld_region_get
## example: ext <- "/ld/human/region/6:25837556..25843455/1000GENOMES:phase_3:KHV?"
## Query region. A maximum of 1Mb is allowed.

ext <- glue::glue("/ld/human/region/{sel.chr}:{sel.pos - range/10}..{sel.pos + range/10}/1000GENOMES:phase_3:PUR?")

r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
stop_for_status(r)
LD.matrix <- as_tibble(fromJSON(toJSON(content(r)))) %>% unnest()
LD.matrix

```

### LD between SNP1 and SNPs

```{r, calc-ld-SNP-SNPS}

## https://rest.ensembl.org/documentation/info/ld_pairwise_get
other.snps <- c("rs199147", "rs4793629", "rs4793628", "rs199143")
## yes, nope, yes
## check this: https://www.ensembl.org/Homo_sapiens/Export/Output/Location?_format=HTML;db=core;output=ld;pop1=1000GENOMES:phase_3:PUR;r=17:50040862-50060861;v=rs199141;vdb=variation;vf=92317

f.extract.ld <- function(SNP.id2 = NULL, SNP.id1 = NULL, POP = "PUR")
{
  ##>>>>> not working
  ext <- glue::glue("/ld/human/pairwise/{SNP.id1}/{SNP.id2}?population_name=1000GENOMES:phase_3:{POP}") 
  
## working
  ##  ext <- "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
  server <- "https://rest.ensembl.org"

#ext <- glue::glue("/ld/human/region/{sel.chr}:{sel.pos - range/2}..{sel.pos + range/2}/1000GENOMES:phase_3:CEU?") ##>> timing out, not working

  r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
stop_for_status(r)

  out <- as_tibble(fromJSON(toJSON(content(r)))) %>% unnest()
  return(out)
}

LD <- purrr::map2(other.snps, snp, f.extract.ld) %>% mutate(r2 = as.numeric(r2)) %>% bind_rows() %>% unnest()

## lets see what the tgenotype data of  SNP3 is. .. 
```





```{r, calc-maf-per-pop}

## https://rest.ensembl.org/documentation/info/variation_id
server <- "https://rest.ensembl.org"

ext <- glue::glue("/variation/human/{dat.bmi.sel$SNP}?content-type=application/json;population_genotypes=1")

r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
stop_for_status(r)

# use this if you get a simple nested list back, otherwise inspect its structure
# head(data.frame(t(sapply(content(r),c))))
(fromJSON(toJSON(content(r))))
## corresponding to : https://www.ensembl.org/Homo_sapiens/Variation/Population?db=core;r=16:53766542-53767542;v=rs1421085;vdb=variation;vf=984887


## read sample files from 1kg
#ext <- glue::glue("/variation/human/{dat.bmi.sel$SNP}?content-type=application/json;genotypes=1")

```


## A complete solution: API provided by sph.umich

[API](http://portaldev.sph.umich.edu/docs/api/v1/?shell#single-variant-statistics)
Accessing precomputed things.


```
## List all available reference panels
curl "http://portaldev.sph.umich.edu/api/v1/statistic/pair/LD/"


## Extract
shell.command <- "curl -G \"http://portaldev.sph.umich.edu/api/v1/statistic/pair/LD/results/\" --data-urlencode \"filter=reference eq 1 and chromosome2 eq '16' and position2 ge 53519169 and position2 le 54119169 and variant1 eq '16:53819169_T/C'\""
system(shell.command)

```



```{r, plot-summarystats-ld, include = TRUE}

p1.color <- ggplot(data = dat.bmi.sel.region) + 
  geom_point(aes(POS, -log10(P), color = r2), shape = 16) + 
  labs(title = "Locuszoomplot for BMI GWAS", subtitle = paste("Summary statistics for chromosome", sel.chr, "from", format((sel.pos - range), big.mark = "'"), "to", format((sel.pos + range), big.mark = "'"), "bp"), caption = paste("Data source:", url)) +
  geom_point(data = dat.bmi.sel.region %>% filter(SNP == "rs1421085"), aes(POS, -log10(P)), color = "black", shape = 16) + scale_color_distiller(type = "div", palette = "Spectral", limits = c(0,1))

#+ gghighlight(SNP == "rs1421085")
# + scale_colour_gradient(limits = c(0,1))

```


```{r, summarystats-genes-ld, include = TRUE, fig.height = 9}

library(patchwork)

p1b <- p1.color + xlab("") + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) + xlim(plot.range)

p1b + p2 + plot_layout(ncol = 1, heights = c(6, 6))

```


## Add LD to locuszoom plot


In the [previous blogpost](https://sinarueeger.github.io/2018/07/30/locuszoomplot/) I showed how to extract annotation from the package `biomaRt` to get closer to a locuszoom plot. 

In this blogpost, we will complete that locuszoomplot by adding the LD information. 


## Stuff from last time, minus the genes

Let's quickly restablish the plot from last time. 

```{r, setup, include = FALSE, warning=FALSE, message=FALSE}
library(showtext)
lippressPackageStartupMessages(library(tidyverse))
theme_set(theme_bw())  ## make all ggplots white-ish
```

Loading the data

```{r, load-data, echo=TRUE, results="hide", cache=TRUE, message = FALSE, warning = FALSE}

## Data Source URL
url <- "https://portals.broadinstitute.org/collaboration/giant/images/2/21/BMI_All_ancestry.fmt.gzip"

#url <- "jenger.riken.jp/1analysisresult_qtl_download/All_2017_BMI_BBJ_autosome.txt.gz"

## Import BMI summary statistics dat.bmi <- read_tsv(file = url) ##
## taking too long, let's use fread instead.

dat.bmi <- data.table::fread(url, verbose = FALSE)

## Rename some columns
dat.bmi <- dat.bmi %>% rename(SNP = SNPNAME, P = Pvalue)

## Extract region
dat.bmi.sel <- dat.bmi %>% slice(which.min(P))
dat.bmi.sel

## range region
range <- 5e+05
sel.chr <- dat.bmi.sel$CHR
sel.pos <- dat.bmi.sel$POS

dat.bmi.sel.region <- dat.bmi %>% filter(CHR == sel.chr, between(POS, sel.pos - 
      range, sel.pos + range))

```

```{r, plot-summarystats, include = TRUE}

p1 <- ggplot(data = dat.bmi.sel.region) + 
  geom_point(aes(POS, -log10(P)), shape = 1) + 
  labs(title = "Locuszoomplot for BMI GWAS", subtitle = paste("Summary   statistics for chromosome", sel.chr, "from", format((sel.pos - range), big.mark = "'"), "to", format((sel.pos + range), big.mark = "'"), "bp"), caption = paste("Data source:", url)) + 
  xlab("") + 
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
print(p1) 

```


There are two things typically shown here. Either the squared correlation of the top SNP with all other SNPs (that would be a vector), or half of the full squared correlation matrix. 

squared correlation = LD, might also be Dprime. 

So how to do this? There are many many options, and I will highlight a few here. I also have a couple of criteria: 
1. I do not want to download any full genomic dataset.
2. I only want to calculate the correlation in a defined range, not for the full genome. 
3. I want to do this in R or from R. 

The reason for 1. is, 





```{r, setup, include = TRUE}
sessionInfo()
```
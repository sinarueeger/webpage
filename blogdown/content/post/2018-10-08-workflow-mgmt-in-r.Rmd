---
title: 'Tidying worflows in R'
description: 'using `drake`'
date: '2018-10-09'
categories: 
  - R
  - data visualisation
tags: 
  - drake
  - R
  - projects
slug: workflow
draft: true
header:
  caption: ''
  image: ''
---

Recently, I started seriously^[Seriously, meaning, different from the previous attempts.] thinking about the tidyness of project folders, and implications of it. 

I was lucky enough to have the opportunity to talk about what I have figured out so far at the [Geneve R User Group](https://www.meetup.com/Geneve-R-User-Group/). While I am not done yet with reflecting on this, I wanted to write down my thoughts that lead to [my presentation](https://sinarueeger.github.io/20181004-geneve-rug/slides#1)^[Thanks to Maëlle for pointing out that this is a good thing to do!]. So all what follows is just "thinking out loud". 

<figure>
<img src="/post/workflow/trailer.mp4" alt="Trailer" align="middle" style="width: 400px;"/>
<figcaption><small>Presentation trailer made with <a href="https://masalmon.eu/2018/10/07/trailer/">Maëlle Salmon's instructions</a>.
</small></figcaption>
</figure>

## What is a "project folder"?

To me a project folder is anything that contains the (R-)scripts necessary to run a data analysis and create the corresponding report. It is like a framed piece of work that you can take and place somewhere else. It is likely to take the form of the Figure from the [R4DS](http://r4ds.had.co.nz/explore-intro.html) book below:

<figure>
<img src="/post/workflow/workflow.png" alt="Drawing of a table." align="middle" style="width: 600px;"/>
<figcaption><small>Adapted from Figure in <a href="http://r4ds.had.co.nz/explore-intro.html">R4DS book</a>.
</small></figcaption>
</figure>
 
Ideally you should be able to take that folder as it is, run it on another computer and get the same results. Unfortunately, this is not always the case - at least with my project folders.

I think that the tidyness of a project folder, how it is structured and how it tells the user to execute what and when, correlate strongly with the whole repeatability, replicability and reproducibility aspect. 

## Why now?

The reason I started to dig deeper into workflow management possibilities in R, is, that I was changing jobs, and I had to clean up my old project folders from almost 5 years of analysing genetic data `r emo::ji("scream")`. And so I faced this gigantic mess, spread over several servers and computers, some version controlled, others not, with implemeted "best practices" from different waves of trying to improve. I tried to clean up as good as I could, but I told myself that this would not happen again. At my [new job](https://fellay-lab.epfl.ch/) I would use version control for everything and I would use something make-like (e.g. [remake](https://github.com/richfitz/remake)) to indicate the "recipe" of a project and be in control of what is recomputed and what is not^[And while at it, I would totally decrease my coffee consumption too and never procrastinate again `r emo::ji("wink")`.].

## Carrot and stick

I have a longtime interest in tidyness in general and from studying my own behaviour I came up with the theory that tidyness is only present when a) somebody tells you to do it, or b) you are rewarded for it. 

Here are some examples: 

- If you want to compile an R-package you have little to no freedom in how to name folders. You must have a given folder and file structure. Otherwise it won't compile. This dictated and unified folder structure makes it easy for R users to understand what is where in an R-package. No matter who coded it. 


<figure>
<img src="/post/workflow/package-files.png" alt="Drawing of a table." align="middle" style="width: 300px;"/>
<figcaption><small>R package structure. Figure from <a href="http://r-pkgs.had.co.nz/package.html.">http://r-pkgs.had.co.nz/package.html</a>.
</small></figcaption>
</figure>

- If you work on several different projects at them same time, it is beneficial to have structure, so that you can quickly dive back into a project.

- Following good practices also leaves you more time to do the fun stuff, like modelling and creating data visualisation. 

## Challenges

I started by wondering, why it is so difficult for me to maintain a tidy folder when sticking to the default folder structure. And I came up with a list (which is certainly going to change over time):

- Having  **different places** for computation (Laptop, Server1, Server2, ...).
- Did not use **`git`** consistently for a long time.
- Unlcear separation of the folders **`data`** (raw input data), `processed-data` and `output-data` (results).
- **Data deliveries**: data hardly ever arrives in one tidy folder, but instead comes at different timepoints and so poses other challenges.
- Having many different **best practices** implemented: so each project would have it's own set of folder names and file naming convention, leading to little **overview of the analysis and its iteration steps** → cleaning, modelling, visualisation, reports.
- Using similar code in many different R scripts → **redundant** code.
- Having no punishment for not cleaning up (and also not really seeing the benefit).


## What I want

Then I asked myself what I want to achieve with implementing (and sticking!) to something new. 

1. Making it easy for colleagues at work to **rerun** (and **understand**) the project → *"repeatability"*
2. Making it easy for others to **rerun** and to **understand** the project → [*"reproducibility"*](https://twitter.com/jtleek/status/759822823552606208)
3. Making it easy for others to rerun the code **with different data** → [*"replicability"*](https://twitter.com/jtleek/status/759822823552606208)

Next I looked for solutions:

- **Tidy folders**
    - clear folder naming, e.g. `data`, `bin`, `code`, but not `data1`, `data2`, `code_old`, `_archive`
    - only files with purposes (no `B_model_old.R`)
- **Clear instructions** → one file should contain a sort of **recipe** of the analysis.
- **Modular code** → using **functions** instead of free floating code.
- **Minimising** redundant computation → **caching** results.
- Using **unit tests**^[Thanks for my colleague Thomas for giving me the idea!].


## The options

There are many different options out there. I was thinking of going back to useing `make`, that I used years ago. Then I came accross [{remake}](https://github.com/richfitz/remake), which seemed just what I needed. A colleague at work was using `stu` and was recommending it. But then the Swiss Insitute of Bioinformatics offered a course on *Make-like declarative workflows with R* thaught by [Kirill Müller](https://github.com/krlmlr), which I could not attend. Luckily, thanks to the awesome [online course material](https://github.com/krlmlr/drake-sib-zurich), I could learn it by myself. 

## Drake

The presentation *Make-like declarative workflows with R* presented the R-package [{drake}](https://github.com/ropensci/drake) (drake = Data Frames in R for Make^[I am still wondering how "Data Frames in R for Make" adds up to "drake" `r emo::ji("thinking")`.]). 

Drake was created by [Will Landau](https://twitter.com/wmlandau) and reviewed by  [rOpenSci](https://ropensci.org/). On the github page of drake it says that drake is a "general-purpose workflow manager for data-driven tasks". Sounds perfect!

The way I understand it, is, that it borrows some features from `make` but adds stuff so that its up to the task of changing data. Therefore it caches runs (future runs only start from the part where something, including data, has changed). It is scalable to parallel computing. And it is intuitive to use, meaning, colleagues can learn it quickly. 


### Getting started

Best is, to run the mini example, and then go from there. Drake has many examples provided, you can check them by running `drake::drake_examples()`.


1. `install.packages("drake")`
1. Run `drake::drake_example("main")` → this will download a folder called `main`.
1. Go to the terminal. You can look at all the files contained in `main` by writing `tree main` (this works on MacOS)

```
main/
├── COPYRIGHT.md
├── LICENSE.md
├── README.md
├── clean.R
├── make.R
├── raw_data.xlsx
└── report.Rmd
```

1. Next, open `make.R`. The key functions are `drake_plan()` and `make()`. 
1. Add the following bit before and after `make(plan)`.

```
config <- drake_config(plan) 
vis_drake_graph(config) 
```
1. Run all code for a first time.
1. Change something (e.g. the plot function).
1. Rerun and watch the colors change in `vis_drake_graph(config)`.
1. Use functions `readd()` and `loadd()` to work with the produced output.
1. checkout `.drake/` folder. This is where all the cached work is stored. 


By running this example, you will see that `drake_plan()` is used to create a recipe of the analysis and `make()` is used to execute that recipe. `make()` will create objects, such as `fit` and `hist` in the example. 

Next, `readd()` is used to return an object from cache. This is handy when we only want to diplay an object. `loadd()` on the other hand is used to load an object into our session (similarly to `load`).

### Examples

I also created [some examples](https://github.com/sinarueeger/workflow-example) that use genetic data. It has four folders:

1. `wild-west`: this is the default. 
2. `wild-west-pro`: same as 1. but with an `README.md`
3. `drake`: implementing 1. into drake.
4. `drake-adv`: implementing 1. into a more realistic folder structure with more hierarchical folders.

1. is mainly used to introduce the analysis. 

The examples use genetic data that was originally used in the [crowdAI openSNP height prediction](https://www.crowdai.org/challenges/opensnp-height-prediction) challenge. The full openSNP data set was prepared by [Olivier Naret](https://github.com/onaret) and can be downloaded [here](https://zenodo.org/record/1442755#.W8BGbVJ9jOQ). The examples use a small subset of the full dataset and can be downloaded [here](https://github.com/sinarueeger/create-data-workflow-example). 


### Resources

Here are a bunch of resources that helped me to understand drake:

- [Github Repo](https://github.com/ropensci/drake)
- My examples: [https://github.com/sinarueeger/workflow-example](https://github.com/sinarueeger/workflow-example)
- [Cheatsheet](https://github.com/krlmlr/drake-sib-zurich/blob/master/cheat-sheet.pdf).
- Check-out [this tutorial](https://github.com/krlmlr/drake-sib-zurich) by [Kirill Müller](https://twitter.com/krlmlr).
- [Best practices](https://ropensci.github.io/drake/articles/best-practices.html) for drake projects.
- Lots of [tutorials](https://github.com/ropensci/drake#tutorials) and [examples](https://github.com/ropensci/drake#examples).


## But wait: drake does not care about messy folders

True! I can have a `make.R` file anywhere and it will still work. 
But I believe that the shift in logic that you have to learn with `drake` makes you care more about folder structure. 

## What is next? 

I want to use drake in a more complex setting. There are also other R-packages that help with project workflows. And I should invest some time to come up with a test suite for data analysis projects. 

But here is what I am dreaming of: a package that has a function `tidy_up(path)` that will create two folders: with the files needed and all other files. It will also tell you: ... 

## When is the right time to tidy

At the Geneve RUG meetup we were also discussing when we think is the right time to tidy up. 

Project folders evolve over time. Especially in the beginning of a project, we are busy figuring things out, wrangling data, fitting models, making plots and telling people what we found out. This can take some time. But at one point we are ready to write a report. 

It is probably at that stage (when we write a report) that we can "frame" that project into something that is "stable" and "portable". 

Although - I am not sure we have to wait that long. I think the benefits of drake (e.g. caching) already help us at an earlier stage. 


## Is it really worth it

I think there is a trade-off between dedicating days to tidying up and not careing about structure at all. Same with tooling. For example, if we use a tool, say `make` but no one else but us knows how to use it, it is going to be hard for colleagues to understand my project folders. 


